{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c89ce5",
   "metadata": {},
   "source": [
    "### Dataset license"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "689f3f20",
   "metadata": {},
   "source": [
    "The research is based on the dataset \"[ATLAS Top Tagging Open Data Set](https://opendata.cern.ch/record/15013)\" from European Organization for Nuclear Research (CERN) which is released under the Creative Commons CC0 waiver allowing open and free use of the data without limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a2269c",
   "metadata": {},
   "source": [
    "### Data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2663971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c020626",
   "metadata": {},
   "source": [
    "The data are split into two orthogonal sets, named train and test and stored in the HDF5 file format, containing 42 million and 2.5 million jets respectively.\n",
    "For the purposes of this study, the dataset test.h5 was chosen due to limitations on computational power and computation time.\n",
    "\n",
    "HDF5 files represent structured data storage, used for organizing and storing data in a hierarchical format. H5 files can contain datasets, groups, and attributes.\n",
    "First, let's examine the structure of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a483c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 File Structure:\n",
      "Dataset: fjet_C2        | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_D2        | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_ECF1      | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_ECF2      | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_ECF3      | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_L2        | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_L3        | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Qw        | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Split12   | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Split23   | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Tau1_wta  | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Tau2_wta  | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Tau3_wta  | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_Tau4_wta  | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_ThrustMaj | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_clus_E    | Shape: (2484117, 200) | Datatype: float32\n",
      "Dataset: fjet_clus_eta  | Shape: (2484117, 200) | Datatype: float32\n",
      "Dataset: fjet_clus_phi  | Shape: (2484117, 200) | Datatype: float32\n",
      "Dataset: fjet_clus_pt   | Shape: (2484117, 200) | Datatype: float32\n",
      "Dataset: fjet_eta       | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_m         | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_phi       | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: fjet_pt        | Shape: (2484117,)     | Datatype: float32\n",
      "Dataset: labels         | Shape: (2484117,)     | Datatype: int32\n",
      "Dataset: weights        | Shape: (2484117,)     | Datatype: float32\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = 'test.h5'\n",
    "\n",
    "# Open the .h5 file for reading\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print('HDF5 File Structure:')\n",
    "    for name, dataset in f.items():  # Loop through all items in the root group\n",
    "        dataset_name = f'Dataset: {name.ljust(14)}'\n",
    "        shape_str = f'| Shape: {dataset.shape}'\n",
    "        datatype_str = f'| Datatype: {dataset.dtype}'\n",
    "        print(f\"{dataset_name} {shape_str.ljust(23)} {datatype_str}\")  # Print name, shape, and datatype of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80999399",
   "metadata": {},
   "source": [
    "The file structure consists of 25 datasets, 21 of which have 1 feature each, and 4 have 200 features each. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c254a6",
   "metadata": {},
   "source": [
    "### Converting to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7cf7af",
   "metadata": {},
   "source": [
    "To facilitate the file structure for processing and analysis, let's extract these datasets separately, concatenate them into one dataset, and upload the results in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753c68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets to extract\n",
    "datasets_one_feature = [\n",
    "    '/fjet_C2', '/fjet_D2', '/fjet_ECF1', '/fjet_ECF2', '/fjet_ECF3',\n",
    "    '/fjet_L2', '/fjet_L3', '/fjet_Qw', '/fjet_Split12', '/fjet_Split23',\n",
    "    '/fjet_Tau1_wta', '/fjet_Tau2_wta', '/fjet_Tau3_wta', '/fjet_Tau4_wta',\n",
    "    '/fjet_ThrustMaj', '/fjet_eta', '/fjet_m', '/fjet_phi', '/fjet_pt',\n",
    "    '/labels', '/weights'\n",
    "]\n",
    "datasets_200_features = [\n",
    "    '/fjet_clus_E', '/fjet_clus_eta',\n",
    "    '/fjet_clus_phi', '/fjet_clus_pt'\n",
    "]\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df_1 = pd.DataFrame()\n",
    "\n",
    "# Open the .h5 file for reading\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    \n",
    "    # Extracting and concatenating datasets with 1 feature\n",
    "    \n",
    "    # Iterate over the specified datasets\n",
    "    for dataset_name in datasets_one_feature:\n",
    "        # If the dataset exists, add it to the DataFrame\n",
    "        if dataset_name in f:\n",
    "            dataset = f[dataset_name]\n",
    "            df_1[dataset_name[1:]] = dataset[:]\n",
    "    \n",
    "     # Extracting and concatenating datasets with 200 features\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    # Iterate over the datasets and append their values to the list\n",
    "    for dataset_name in datasets_200_features:\n",
    "        dataset_200 = f[dataset_name]\n",
    "        datasets.append(dataset_200[:])\n",
    "\n",
    "    # Concatenate the datasets along the second axis (axis=1) using NumPy\n",
    "    concatenated_data = np.concatenate(datasets, axis=1)\n",
    "    \n",
    "    # Generate column names\n",
    "    column_names = []\n",
    "    for dataset_name in datasets_200_features:\n",
    "        for i in range(200):\n",
    "            column_names.append(f'{dataset_name[1:]}_{i}')\n",
    "\n",
    "    # Convert to pandas DataFrame with column names\n",
    "    df_200 = pd.DataFrame(concatenated_data, columns=column_names)\n",
    "    \n",
    "# Concatenate df_1 and df_200 along axis=1 using NumPy\n",
    "# I use np.concatenate instead of pd.concat because the latter crushed the system and didn't provide any results\n",
    "result_array = np.concatenate([df_1.to_numpy(), df_200.to_numpy()], axis=1)\n",
    "\n",
    "# Convert the concatenated array to a DataFrame\n",
    "result_df = pd.DataFrame(result_array, columns=list(df_1.columns) + list(df_200.columns))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "result_df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657d6f77",
   "metadata": {},
   "source": [
    "The dataset has been transformed and saved into the file result.csv. Let's verify the information in the obtained dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef37acf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2484117 entries, 0 to 2484116\n",
      "Columns: 821 entries, fjet_C2 to fjet_clus_pt_199\n",
      "dtypes: float64(821)\n",
      "memory usage: 15.2 GB\n"
     ]
    }
   ],
   "source": [
    "result_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
